---
title: "Lesson 19 Inference for Independence of Categorical Data"
output: 
  html_document:
    theme: cerulean
    toc: true
    toc_float: false
---

<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
</script>

<div style="float:right;width=40%;">
<br/>
<div style="padding-left:10%;">**Optional Lesson Video**</div>
<iframe width="90%" align="right" src="https://www.youtube.com/embed/videoseries?list=PLaZryQtbPQC9acEfJHNYCs9N93R2CJ8zB" frameborder="1" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

## Lesson Outcomes

<a href="javascript:showhide('oc')"><span style="font-size:8pt;">Show/Hide Outcomes</span></a>
<div id="oc" style="display:none;">
By the end of this lesson, you should be able to do the following.

**Regarding Hypothesis Testing for a Test of independence for categorical data: **

* State the null and alternative hypothesis for the chosen test. 
* Calculate the test-statistic, df and p-value of the hypothesis test.
* Assess the statistical significance by comparing the p-value to the α-level.
* Check the requirements for the hypothesis test.
* Show the appropriate connections between the numerical and graphical summaries that support the hypothesis test. 
* Draw a correct conclusion for the hypothesis test.
  
**Regarding Hypothesis Testing for a goodness of fitness test:**

* State the null and alternative hypothesis for the chosen test. 
* Calculate the test-statistic, df and p-value of the hypothesis test.
* Assess the statistical significance by comparing the p-value to the α-level.
* Check the requirements for the hypothesis test.
* Show the appropriate connections between the numerical and graphical summaries that support the hypothesis test. 
* Draw a correct conclusion for the hypothesis test.
</div>
<br>



<div style="clear:both;"></div>
<br/>

## The Chi-squared Test of Independence

The chi-squared test of independence allows us to determine if two different categorical variables are related to each other. Here are some questions that could be answered with a chi-squared test of independence.

* Does the education level obtained by your father impact the education level you will obtain in life? (Here education level could be defined to be one of: High School, Associates Degree, Bachelor's Degree, or Graduate Degree. The two variables we would be comparing would be the child's education level and their father's education level.)
* Does the marital status of a person (single, married, widowed, or divorced/separated) relate to the overall happiness of that person (very happy, happy, not too happy)?
* Does a student's major (say Business, Nursing, Biology, or Math) have any impact on their ability to get a good paying job (say above \$50,000 per year versus below \$50,000) after graduating from college?

In each of these examples, there were two sets of categorical data that were being compared to see if there was any relation between those variables. An important word that will be used in this lesson to talk about variables being related or not is the word *independent*. Things that **are independent** of each other have absolutely no relation to each other. On the other hand, when things are related to each other, that means that they are **not independent of each other**. Keep this in mind as you read this lesson. Independent means not related, and *not independent* means *related*.




<!--

People seek chiropractic care for different reasons. We may want to know if those reasons are different for Europeans than for Americans or Australians. This question can be expressed as "Do reasons for seeking chiropractic care depend on the location in which one lives?"

This question has only two possible answers: "yes" and "no." The answer "no" can be written as "Motivations for seeking chiropractic care and one's location are independent." (The statistical meaning of "independent" is too technical to give here. However, for now, you can think of it as meaning that the two variables are not associated in any way. For example, neither variable depends on the other.) Writing the answer "no" this way allows us to use it as the null hypothesis of a test. We can write the alternative hypothesis by expressing the answer "yes" as "Motivations for seeking chiropractic care and one's location are not independent." (Reasons for wording it this way will be given after you've been through the entire hypothesis test.)

To prepare for the hypothesis test, recall that our hypothesis tests always measure how different two or more things are. For example, in the 2-sample $t$-test, we compare two population means by seeing how different they are. In a test of one proportion, we measure the difference between a sample proportion and a population proportion. Each of these tests requires some information about at least one parameter. That information is given in the null hypothesis of the test, which we've always been able to write with one or more "=" signs, because we've always used numeric parameters.

Unfortunately, we have no parameter we can use to measure the independence of the variables "location" and "motivation". Nevertheless, we have to be able to calculate a $P$-value, and the only approach we have so far is to measure differences between things. "Difference" means "subtraction" in Statistics, and if the measurements are categorical, we cannot subtract them. Therefore, as in the other lessons of this unit, we will count occurrences of each value of each variable to get some numbers. (The example that follows will show how this is handled.) The numbers we get will be called "counts" or "observed counts".

When we have our observed counts in hand, software will calculate the counts we should *expect* to see, *if the null hypothesis is true.* We call these the "expected counts." The software will then subtract the observed counts from the expected counts and combine these differences to create a single number that we can use to get a $P$-value. That single number is called the $\chi^2$ test statistic. (Note that $\chi$ is a Greek letter, and its name is "ki", as in "kite". The symbol $\chi^2$ should be pronounced "ki squared," but many people pronounce it "ki-square.")

In this course, software will calculate the $\chi^2$ test statistic for you, but you need to understand that the $\chi^2$ test statistic compares the observed counts to the expected counts---that is, to the counts we should expect to get if the null hypothesis is true. The larger the $\chi^2$ test statistic is, the smaller the $P$-value will be. If the $\chi^2$ test statistic is large enough that the $P$-value is less than $\alpha$, we will conclude that the observed counts and expected counts are too different for the null hypothesis to be plausible, and will therefore reject $H_0$. Otherwise, we will fail to reject $H_0$, as always.

For organizational reasons, counts are traditionally arranged in a table called a "contingency table." One variable is chosen as the "row variable," so called because its values are the row headers for the table. The other variable is called the "column variable," because its values are the column headers. Different $\chi^2$ distributions are distinguished by the number of degrees of freedom, which are determined by the number of rows and columns in the table: 

$$df = (\text{number of rows }-1)(\text{number of columns }-1)$$

Note that the number of degrees of freedom does not depend on the number of subjects in the study.

-->


<br>


### Case Study: Chiropractic Care

<div style="float:right;padding:10px;">
<img src="./Images/chiropracticCare.jpeg" width="400px;">
</div>

<img src="./Images/Step1.png">

A [study was conducted](https://drcharlesblum.com/About%20Us/BlumJCCASep2008.pdf) to determine why patients in Australia, Europe, and the U.S.A. seek chiropractic care<!--<cite>Blum08</cite>-->.  Patients were classified based on their location (Australia, Europe, or the U.S.A.) and their motivation for seeking treatment.  Using descriptions developed by Green and Krueter, patients were asked which of the five reasons led them to seek chiropractic care <!--<cite>Blum08,Green99</cite>-->:

- *Wellness*: defined as optimizing health among the self-identified healthy
- *Preventive health*: defined as preventing illness among the self-identified healthy
- *At risk*: defined as preventing illness among the currently healthy who are at heightened risk to develop a specific condition
- *Sick role*: defined as getting well among those self-perceived as ill with an emphasis on therapist-directed treatment
- *Self care*: defined as getting well among those self-perceived as ill favoring the use of self vs. therapist directed strategies

The research question was whether people's motivation for seeking chiropractic care was related to their location: Europe, Australia, or the United States or not. The hypothesis test used to address this question was the chi-squared ($\chi^2$) test of independence. (Note that the Greek letter $\chi$ is pronounced, "ki" as in "kite.")

The null and alternative hypotheses for this chi-squared test of independence are:
$$
\begin{array}{rl}
H_0\colon & \text{The location and the motivation for seeking treatment are independent} \\
H_a\colon & \text{The location and the motivation for seeking treatment are not independent} \\
\end{array}
$$

Note: When speaking of the hypotheses in the absence of a context, we can write them in the form
$$
\begin{array}{rl}
H_0\colon & \text{The row variable and the column variable are independent} \\
H_a\colon & \text{The row variable and the column variable are not independent.} \\
\end{array}
$$
But when there's a context, please make sure you write your hypotheses in terms of the context.

<img src="./Images/Step2.png">

The researchers reported on their data collection procedures with the following statement. "Using an international convenience sample of Sacro-Occipital Technique (SOT) practitioners, 1316
consecutive patients attending 27 different chiropractic
clinics in the USA, Europe and Australia completed a
one-page survey on intake to assess reason for seeking
care. A forced choice response was obtained
characterizing the patient’s reason for seeking
chiropractic care."

<br/>

<img src="./Images/Step3.png">

The data from the study are summarized in the following table of counts. (This is sometimes called a *contingency table*.) <!--<cite>Blum08</cite>-->

+---------------+----------+------------+---------+-----------+-----------+-------+
| Location      | Wellness | Preventive | At Risk | Sick Role | Self Care | **Total** |
|               |          | Health     |         |           |           |       |
+===============+:========:+:==========:+:=======:+:=========:+:=========:+:======:+
| Europe        | 23       | 28         | 59      | 77        | 95        | **282**   |
+---------------+----------+------------+---------+-----------+-----------+-------+
| Australia     | 71       | 59         | 83      | 68        | 188       | **469**   |
+---------------+----------+------------+---------+-----------+-----------+-------+
| United States | 90       | 76         | 65      | 82        | 252       | **565**   |
+---------------+----------+------------+---------+-----------+-----------+-------+
| **Total**     | **184**  | **163**    | **207** | **227**   | **535**   | **1316**  |
+---------------+----------+------------+---------+-----------+-----------+-------+
|               |          |            |         |           |           |       |
+---------------+----------+------------+---------+-----------+-----------+-------+

: **Motivation for Choosing to Seek Chiropractic Care** 

While a table of counts, or contingency table, is helpful in describing the relationship between two categorical variables like *location* and *motivation*, a clustered bar chart makes it much easier to visually compare and contrast the observed counts.

### R Instructions for Clustered Bar Charts

<div class="SoftwareHeading">R Instructions</div>
<div class="Software">

First, the data must be entered into an R object using the `cbind( )` or `rbind( )` functions. 

<div style="padding:15px;color:darkgray;">

While the counts don't have to be named as shown below, it is a good way to stay organized. Pressing both "Shift" and "Enter" (or "Shift" and "Return") after each line of code will indent your code automatically and keep it more organized.

</div>


```{r}
motivation_table <- cbind( Europe = c(Wellness = 23, 
                                      `Preventative Health` = 28,
                                      `At Risk` = 59,
                                      `Sick Role` = 77,
                                      `Self Care` = 95),
                           Australia = c(Wellness = 71,
                                         `Prevantative Health` = 59,
                                         `At Risk` = 83,
                                         `Sick Role` = 68,
                                         `Self Care` = 188),
                           `United States` = c(Wellness = 90,
                                               `Preventative Health` = 76,
                                               `At Risk` = 65,
                                               `Sick Role` = 82,
                                               `Self Care` = 252))
```

The above code created a table that could be displayed by typing the name of the table:

```{r, comment=NA}
motivation_table
```

Once the table of observed counts is created, then it can be turned into a clustered bar chart using the `barplot( )` code with the optional commands of 

* `beside=TRUE` puts the bars side-by-side. Not using `beside=TRUE` results in a stacked bar chart.

* `legend.text=TRUE` adds a legend to the graph. Sometimes the legend covers the bars, so it is useful in that case to use `ylim=c(0, some number)` so that the legend is moved off of the bars.

```{r}
barplot(motivation_table, beside=TRUE, legend=TRUE)
```

Notice that the legend is on top of the bars for the United States in the above plot. If we increased the y-axis from say 0 to 500 (instead of the current 250 showing as the highest value on the y-axis) then the legend would no longer cover the bars. We could also color the plot by providing enough colors for each of the legend entries.

```{r}
barplot(motivation_table, beside=TRUE, legend=TRUE,
        ylim=c(0,500), #extend the y-axis to 500
        col=c("skyblue4","green3","orange","red3","skyblue"))
```

<br/>
</div>

<br>


<br>

The above bar plot of observed counts shows that for Australia and the United States, it seems that the predominant motivation that people choose to seek chiropractic care is for *self care*. In Europe, the *wellness* motivation seems especially low. 

<br/>

<img src="./Images/Step4.png">

Before making any strong conclusions about the data depicted in a bar chart it is important to conduct the chi-squared test of independence. The $P$-value from this test will help us know if we should reject the null hypothesis or not. If we fail to reject the null hypothesis, then *motivation* and *location* are independent (i.e., not related). So any patterns we are seeing in the bar plot can be attributed to random chance. However, if we reject the null hypothesis then we can claim that *motivation* and *location* are **not independent** (meaning they are related) and we can make conclusions from the patterns showing in the bar plot.

### R Instructions for Performing a Chi-squared Test of Independence


<div class="SoftwareHeading">R Instructions</div>
<div class="Software">

To perform a chi-squared test of independence in R, use the `chisq.test( )` function. Using this function requires that you have previously made a table of counts. (Review the [R Instructions for Clustered Bar Charts](Lesson19.html#r-instructions-for-clustered-bar-charts) to review how to create a table of counts in R.)

```{r, comment=NA}
#motivation_table is a table of counts created previously.

chisq.test(motivation_table)
```

The "X-squared" value of 49.743 is the test statistic of the test. Technically, it should read $\chi^2 = 49.743$ but the words "X-squared" are used to represent the Greek character chi-squared ($\chi^2$) in the output of the test. The **df** stands for degrees of freedom. The p-value is clearly stated.

</div>

<br/>

Recall that the hypotheses of this test were:

$~~~~~H_0\colon$ Location and the motivation to visit a chiropractor are independent.

$~~~~~H_a\colon$ Location and the motivation to visit a chiropractor are not independent.

Let $\alpha=0.05$.

The test statistic is: $\chi^2 = 49.743$, with $df=8$ and $P$-value = 4.58e-08 = 0.0000000458. This allows us to reject the null hypothesis and conclude that location and the motivation to visit a chiropractor are not independent (the motivation is associated with the location).


### Requirements

The following requirements must be met in order to conduct a $\chi^2$ test of independence:

1. The sample of data should be representative of the full population. This is most likely to happen when simple random sampling is used to obtain a sample from the population.

    * In this study, a convenience sample was used. So there could be some doubt as to whether these individuals are representative of all individuals in each country that seek chiropractic care.

2. Each expected count must be greater than or equal to 5.

    * In this study, all expected counts were greater than 5.
    
    * To check expected counts in R, use the code:
    
    ```{r, comment=NA}
    chisq.test(motivation_table)$expected
    ```

    * As shown in the above table, the smallest expected count is 34.92857, which is well above the required 5.
    

<img src="./Images/Step5.png">

People in Europe, Australia, and the United States evidently have different reasons for seeking chiropractic care. It appears that individuals in Europe are much more likely to seek chiropractic care in the sick role than individuals in the United States and Australia. The Europeans are also less likely to visit a chiropractor for wellness reasons.

<br>

## Other considerations

### Swapping the Row and Column Variables

There is no general guideline for deciding which variable is the row variable and which variable is the column variable in a $\chi^2$ test of independence. To see why not, complete the questions that follow.

<div class="QuestionsHeading">Answer the following questions:</div>
<div class="Questions">
1. Re-do the $\chi^2$ test of independence for the chiropractic care data, but use "Motivation" as the row variable.  Then compare the degrees of freedom, $\chi^2$ test statistic, and $P$-value of this test, with the degrees of freedom, $\chi^2$ test statistic, and $P$-value for the test conducted above, when "Location" was the row variable.

<a href="javascript:showhide('Q1')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q1" style="display:none;">
- In both tests, $df = 8$, $\chi^2 = 49.743$, and the $P$-value is $4.58 \times 10^{-8}  < 0.05 = \alpha$. They are the same for both tests.
</div>
<br>

2. What do you conclude about swapping the row and column variables in a $\chi^2$ test of independence?

<a href="javascript:showhide('Q2')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q2" style="display:none;">
- Swapping the row and column variables in a $\chi^2$ test of independence does not change the conclusion of the test. 
</div>
&nbsp;
</div>
<br>

There may be no general guideline for deciding which variable is the row variable, but the graphics produced by your software may depend on this decision. For example, R will give you a different clustered bar chart when you use "Location" as the row variable than when you use "Motivation" as the row variable. Sometimes, choosing one of the variables as the row variable makes the clustered bar chart easier to understand. 

### Why $H_a$ is Worded As It Is

Recall that in the chiropractic care example, the hypotheses for the $\chi^2$ test of independence were

$H_0\colon$ Location and the motivation to visit a chiropractor are independent.
$H_a\colon$ Location and the motivation to visit a chiropractor are not independent.

You may wonder why we don't write "$H_a\colon$ The motivation to visit a chiropractor depends on location." Well, couldn't we say just as easily that location depends on the motivation to visit a chiropractor? It may seem a little strange when phrased this way. Let's use the following exercises to look briefly at a somewhat less strange example, then return to this example.

<div class="QuestionsHeading">Answer the following questions:</div>
<div class="Questions">
3. Suppose you want to know whether a student's stress level and the degree to which they feel a need to succeed are independent. What should your hypotheses be?

<a href="javascript:showhide('Q3')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q3" style="display:none;">
- $H_0\colon$ Stress level and the need to succeed are independent.
- $H_a\colon$ Stress level and the need to succeed are not independent.
</div>
<br>

4. For their alternative hypothesis, a student erroneously writes "$H_a\colon$ Stress level depends on the need to succeed." If they reject $H_0$, what will they conclude?

<a href="javascript:showhide('Q4')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q4" style="display:none;">
- They will conclude that a student's stress level depends on their need to succeed.
</div>
<br>

5. Another student erroneously writes "$H_a\colon$ Need to succeed depends on stress levels." If they reject $H_0$, what will they conclude?

<a href="javascript:showhide('Q5')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q5" style="display:none;">
- They will conclude that the degree to which a student feels a need to succeed depends on their stress level.
</div>
<br>

6. Could it be that a student's need to succeed depends on their stress level? Could it be that their stress level depends on their need to succeed? How can the $\chi^2$ test of independence distinguish between these two possibilities?

<a href="javascript:showhide('Q6')"><span style="font-size:8pt;">Show/Hide Solution</span></a>
<div id="Q6" style="display:none;">
- Students that feel a more intense need to succeed than others might very well experience higher stress levels. Likewise, a student who feels their stress levels rising might subconsiously feel that success will decrease their stress level, which could result in their feeling an increased need to succeed.

- The $\chi^2$ test statistic and the $P$-value will be the same, whether we write down the correct alternative hypothesis or one of the two erroneous ones mentioned above. The $\chi^2$ test of independence is not capable of telling whether stress levels depend on the need to succeed or whether the need to succeed depends on the stress level.

- If swapping the row and column variables made a difference in the outcome of the hypothesis test, then the test might be able to tell which variable depends on the other. But swapping the row and column variables does not change the outcome of the test.

- The full truth is worse than this: It may be that one's need to succeed and one's stress level depend on each other. It may be that neither depends on the other, but that both depend on something else, in a way that makes it look like they depend on each other. The $\chi^2$ test of independence is incapable of distinguishing among the many possible kinds of dependence.
</div>
&nbsp;
</div>
<br>

According to the exercises you just did, we are not justified in writing an alternative hypothesis that specifies which variable depends on which. Could we write "$H_a\colon$ Stress level and need to succeed are dependent"? After all, "independent" and "dependent" are opposites, aren't they? This may seem reasonable, but we have to be careful of the technical terms. Statisticians have gone to some trouble to carefully define "independent." They have not defined "dependent." (As suggested by the exercises you just did, dependence is complicated, perhaps too complicated to be able to be defined conveniently.) They use the phrase "not independent" as the opposite of "independent." So will we, writing "$H_a\colon$ Stress level and need to succeed are not independent."

Likewise, in the chiropractic care example, we can't say in the alternative hypothesis that location depends on motivation, nor that motivation depends on location, nor that each depends on the other, nor that both depend on something else, nor that location and motivation are dependent. Instead, we write "$H_a\colon$ The location and the motivation for seeking treatment are not independent," as statisticians do.
<!--

## The $\chi^2$ (Chi-squared) Goodness of Fit Test
This test is used to compare the observed counts of two or more categories to the expected counts for those same categories. For example, the Mars company claims that the colors of M&Ms are distributed as follows: 24% Blue, 13% Brown, 16% Green, 20% Orange, 13% Red, 14% Yellow. (see http://joshmadison.com/2007/12/02/mms-color-distribution-analysis/) These are the expected proportions (not counts). In a bag of $200$ M&Ms, the expected number of Blue M&Ms is $48$, the expected number of Brown M&Ms is $26$, etc.

To verify the Mars company claim, you could buy several bags of M&Ms and count the number of each color. These would be the observed counts. The $\chi^2$ (Chi-squared) Goodness of Fit Test can be used to compare the expected counts to the observed counts and decide if they are similar or not.

The test is based on the $\chi^2$ statistic that is defined here:

$\chi^2 = \Sigma \frac{(Observed - Expected)^2}{Expected}$

The $\chi^2$ statistic can be used to conduct a hypothesis test.

We illustrate this test using a Sudden Infant Death Syndrome (SIDS) study conducted in King County Washington. The research question in this study was, "Do SIDS deaths occur uniformly across all four seasons?" We will conduct this hypothesis test using a level of significance $\alpha = 0.05$. The null hypothesis is that the answer to this question is, "Yes." So the null and alternative hypotheses can be expressed as follows.

$H_0:$ SIDS deaths are equally likely in winter, spring, summer, and fall
$H_a:$ SIDS deaths are not equally likely in winter, spring, summer, and fall

The number if SIDS deaths that occurred during the observation period in each season were: 78 (winter), 71 (spring), 87 (summer), 86 (fall). The total number of deaths is $78 + 71 + 87 + 86 = 322$. So the expected number of SIDS deaths in each season is $322/4 = 80.5$.

Then $\chi^2 = \frac{(78 - 80.5)^2}{80.5} + \frac{(71 - 80.5)^2}{80.5} + \frac{(87 - 80.5)^2}{80.5} + \frac{(86 - 80.5)^2}{80.5} = 2.1$.

The sample data (observed values) and the the expected counts are summarized in this table.

<center>
{| class="basic" style="text-align:center"
! Season || Winter || Spring || Summer || Fall
|-
! Expected Proportion ||  80.5 || 80.5 || 80.5 || 80.5 
|-
! Observed Count || 78 || 71 || 87 || 86
|-
|}
</center>

The degrees of freedom $df$ equals the number of categories minus one or $df = 4 - 1 = 3$. The $P$-value is the probability that $\chi^2$ is greater then the observed value of the test statistic, or $P(\chi^2 > 2.1)$. This probability is the area under the curve to the right of $2.1$ of a $\chi^2$ distribution curve, illustrated here.

insert graphic

In this case, the $P$-value = 0.5519. Since the $P$-value = 0.5519 > 0.05 = $\alpha$, we fail to reject the null hypothesis. This means there is not enough evidence to conclude that the proportion of SIDS deaths is different from one season to another.


See - http://wiener.math.csi.cuny.edu/Statistics/R/simpleR/stat013.html


Another example: The letter distribution of the 5 most popular letters in the English language is known to be approximately

<center>
{| class="basic" style="text-align:center"
! Letter || E || T || N || R || O
|-
! Frequency ||  29 || 21 || 17 || 17 || 16 
|-
|}
</center>

That is, when either E, T, N, R, O appear, on average 29 times out of 100 it is an E and not the other 4. This information is useful in cryptography to break some basic secret codes.

We want to test the null hypothesis against the alternative hypothesis as follows.

$H_0:$ The frequency of E, T, N, R, O is consistent with English
$H_a:$ The frequency of E, T, N, R, O is not consistent with English

A text of  unknown origin is analyzed and the number of E, T, N, R, and O's is counted. The following distribution is found.

<center>
{| class="basic" style="text-align:center"
! Letter || E || T || N || R || O
|-
! Count ||  100 || 110 || 80 || 55 || 14 
|-
|}
</center>

We now do a chi-square goodness of fit hypothesis test to see if the letter frequencies for this text are consistent with the English language or not.

The chi-squared test requires the independence of each letter, which is not quite true in most languages. Even so, this type of analysis reveals valuable insights.

In this case $\chi^2 = 55.3955$, $df = 4$, and the $P$-value = 2.685e-11. Remember, the $P$-value is the probability of obtaining a test statistic at least as extreme as the one you calculated, assuming the null hypothesis is true. Since the $P$-value is effectively 0, it is very unlikely that this text is written in English.

Remark: need to add Excel and SPSS instructions.

-->

### No Confidence Intervals

We do not calculate confidence intervals when working with contingency tables. Think about it: With three rows and five columns in the table for the chiropractic care example, there are 15 proportions, which means there would be 105 pairs of proportions to compare. How could we possibly interpret a collection of 105 confidence intervals? Also, if our confidence level is 95%, we would expect that about 5 of our confidence intervals would not contain the true difference between proportions, but we wouldn't know which ones. Rather than take the risks this would cause, the Statistics culture has agreed not to calculate confidence intervals for contingency tables.

<!-- TO-DO LIST

## To-do list for the authors of this wiki
- Make sure all the vocabulary is defined.
- Add another example.
- Test of several proportions?
- Goodness-of-fit tests
- Lesson summary
- Add an optional section that shows how the $\chi^2$ statistic is calculated.

-->

<br>

## Summary

<div class="SummaryHeading">Remember...</div>
<div class="Summary">

- The **$\chi^2$ hypothesis test** is a test of independence between two variables. These variables are either associated or they are not. Therefore, the null and alternative hypotheses are the same for every test:
$$
\begin{array}{1cl}
H_0: & \text{The (first variable) and the (second variable) are independent.} \\
H_a: & \text{The (first variable) and the (second variable) are not independent.}
\end{array}
$$

- The **degrees of freedom ($df$)** for a $\chi^2$ test of independence are calculated using the formula $df=(\text{number of rows}-1)(\text{number of columns}-1)$

- In our hypothesis testing for $\chi^2$ we never conclude that two variables are *dependent*. Instead, we say that two variables are *not independent*.

- To create a clustered bar chart in R first requires using either `cbind( )` or `rbind( )` to create a table of observed counts, and then using `barplot( , beside=TRUE, legend.text=TRUE)` to create the plot. Review this by [clicking here](Lesson19.html#r-instructions-for-clustered-bar-charts).

- To perform a chi-squared test of independence in R, use the `chisq.test( )` with your table of observed counts placed inside the function. Review this by [clicking here](Lesson19.html#r-instructions-for-performing-a chi-squared-test-of-independence).

- To check the requirements of a chi-squared test of independence, use the code `chisq.test(your_table_of_counts)$expected` where `your_table_of_counts` is the table of counts you made. Look to see that all expected counts are greater than 5.

<br>
</div>
<br>

## Navigation

<center>
| **Previous Reading** | **This Reading** | **Next Reading** |
| :------------------: | :--------------: | :--------------: |
| [Lesson 18: <br> Inference for Two Proportions](Lesson18.html) | Lesson 19: <br> Inference for Independence of Categorical Data | [Lesson 20: <br> Review for Exam 3](Lesson20.html) |
</center>
